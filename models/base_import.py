from odoo import models, fields
import pandas as pd
import csv
import base64
import time
import numpy as np
from xmlrpc import client
from io import BytesIO
import openpyxl

#TODO: remove extra param from execute_Import and from rpc call in base_import_actions.js
#TODO: add external dependencies in manifest

class BSAImport(models.TransientModel):
    _inherit = 'base_import.import'

    attr_val_file = fields.Binary('Attribute/Value File', help="File containing attribute/value data generated by cleaning script", attachment=False) 
    clean_file = fields.Binary('Clean File', help="File containing clean data generated by cleaning script", attachment=False)

    def execute_import(self, user, password, db, url, fields, columns, model_name):
        print('func called')
        """
        Driver function for the class
        This function is the main function that is called to run the script

        :param string user: the username of the user, typically the email address
        :param string password: an api key provided by the user
        :param string url: the url of the odoo server
        :param string db: the database name
        :param list[string] fields: a list of fields to be imported
        :param list[string]columns: a list of columns.
        :param string model_name: the name of the model to be imported
        :rtype: None

        Whenever possible, we create multiple records with one api call instead of creating one record at a time 
        in order to reduce unnecessary overhead
        This is why the functions that create records, such as 
        create_attribute_records and add_attributes_and_values have helper functions to make api calls

        
        """

        start = time.time()
        #TODO: change js state if error

        common = client.ServerProxy('{}/xmlrpc/2/common'.format(url))
        uid = common.authenticate(db, user, password, {})
        models = client.ServerProxy('{}/xmlrpc/2/object'.format(url))

        #TODO: handle different types of file upload

        #Generates attr-val file
        attr_val_generator = DirtyToAttributeValues()
        attr_val_file = attr_val_generator.main(self.file, ['b','c','e','f','g','h','i','j','k'])

        #Generates clean file
        clean_generator = DirtyToClean()
        clean_file = clean_generator.main(self.file, ['a','d','l','m','n'], ['b','c','e','f','g','h','i','j','k'])

        self.write({
            'attr_val_file': attr_val_file,
            'clean_file': clean_file
        })


        #TESTS
        pd.options.display.max_columns = None
        clean_df = pd.read_excel(BytesIO(clean_file), engine='openpyxl')
        print(clean_df.head(50))

        attr_val_dict = self.create_attr_val_dict(fields, columns)
        database_ids = self.create_attribute_records(db, uid, password, models, attr_val_dict, model_name)
        product_field_information = self.get_field_information(db, uid, password, models, fields, columns)
        if not product_field_information:
            return None
        self.add_attributes_and_values(db, uid, password, models, database_ids, attr_val_dict, product_field_information,fields,columns)

        end = time.time()
        print(end - start)

        return []


    def create_attr_val_dict(self,fields,columns):

        """
        Convert attribute/value data to a dictionary

        :param list[string] fields: a list of fields to be imported
        :param list[string]columns: a list of columns corresponding to the fields
        :rtype Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        
        There are three layers of dictionarys in attr_val_dict:
        Outermost dictionary has attribute names as keys and dictionaries as values
        The middle layer has two hardcoded keys:
        'attribute_external_id', which is the external id of the attribute
        'values_external_id', which is another dictionary
        The innermost dictionary's keys are the names of the values and the values are the external ids of the values
        
        
        Example 
        Original excel file
        Attribute_Name,Attribute_External_ID,Value_Name,Value_External_ID
        Color of Car Body,car_body_color,White,car_body_white
        ,,Green,car_body_green
        Color of Car Trim,car_trim_color,White,car_trim_white
        ,,Green,car_trim_green
        
        create_attr_val_dict() will return:
        {
            'Color of Car Body', {
                'attribute_external_id': 'car_body_color',
                'values': {
                    'White': 'car_body_white',
                    'Green': 'car_body_green'
                }
            }
            'Color of Car Trim', {
                'attribute_external_id': 'car_trim_color'
                'values': {
                    'White': 'car_trim_white',
                    'Green': 'car_trim_green'
                }
            }
        }
        """

        attr_val_df = pd.read_excel('../data/attr-val.xlsx')

        attr_val_dict = {}
        curr_attribute = None
        
        for row in range(0, len(attr_val_df)):
            if not pd.isna(attr_val_df['name'][row]):            
                curr_attribute = str(attr_val_df['name'][row]).strip()
                attr_val_dict[curr_attribute] = {}
                attr_val_dict[curr_attribute]['attribute_external_id'] = attr_val_df['id'][row]
                attr_val_dict[curr_attribute]['values'] = {}

            curr_val_name = str(attr_val_df['value_ids/name'][row]).strip()
            curr_val_external_id = str(attr_val_df['value_ids/id'][row])
            
            attr_val_dict[curr_attribute]['values'][curr_val_name] = curr_val_external_id

        return attr_val_dict


    def create_attribute_records(self, db, uid, password, models, attr_val_dict, model_name):

        """
        Reads from attribute-value excel file and creates corresponding attribute and value records in the database
        Note that there are hardcoded default values for the fields create_variant and display_type.
        returns a dictionary of database ids to avoid making api calls to search for records
 
        :param string db: name of the database.
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        :rtype Dictionary database_ids: dictionary that maps attribute and value external ids to their database ids.
        """

        CREATE_VARIANT_DEFAULT = 'always' #hardcoded default values as per requirements
        DISPLAY_TYPE_DEFAULT = 'radio'
        VISIBILITY_DEFAULT = 'visibile'
        attribute_id_batch = [] #keeping the batch
        MAX_BATCH_SIZE = 100
        database_ids = {}

        attribute_ordered = [] #storing the attributes for each attribute in the same order as the keys of the dictionary
        for attribute in attr_val_dict.keys():
            if len(attribute_id_batch) >= MAX_BATCH_SIZE:
                self.attribute_batch_calls(self, db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids, model_name)
                attribute_id_batch = []
                attribute_ordered = []

            #list of dictionary ids
            attribute_id_batch.append({
                'name': attribute,
                'create_variant': CREATE_VARIANT_DEFAULT,
                'display_type': DISPLAY_TYPE_DEFAULT,
            })


            attribute_ordered.append(attribute)

        if len(attribute_id_batch) > 0:
            self.attribute_batch_calls(db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids, model_name)
        return database_ids

    def get_field_information(self, db, uid, password, models, fields, columns):

        """
        retrieves informations about the fields of a given model from the database. currently hardcoded to product.template
        returns a dictionary that makes it much easiear to create records later

        :param string db: name of the database
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param list[string] fields: a list of fields to be imported
        :param list[string] columns: a list of columns corresponding to the fields
        :rtype Dictionary product_field_information: nested dictionary mapping column names to information about the corresponding field


        Example for product.template
        
        columns = ['Product Name', 'Company']
        fields = ['name', 'company_id']
        product_field_information = {
            'Product Name': {
                'name': 'name',
                'type': 'char',
            },
            'Company': {
                'name': 'company_id',
                'type': 'many2one',
                'relation': 'res.company',
            }
        }


        """
        
        product_template_fields = models.execute_kw(db, uid, password, 'product.template', 'fields_get', [])
        product_field_information = {}

        for i in range(0, len(columns)):
            columns[i].strip() 
            if columns[i] == 'attribute' or columns[i] == 'value':
                continue
            elif not fields[i]:      
                return None
            else:                    
                curr_col = columns[i]
                product_field_information[curr_col] = {}
                product_field_information[curr_col]['name'] = fields[i]
                field_type = product_template_fields[fields[i]]['type']
                product_field_information[curr_col]['type'] = field_type
                if field_type == 'many2many' or field_type == 'one2many'or field_type == 'many2one':
                    product_field_information[curr_col]['relation'] = product_template_fields[fields[i]]['relation']
        return product_field_information


    def attribute_batch_calls(self, db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids,model_name):
        
        """
        makes api calls to create attributes and values in the database

        :param string db: name of the database
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param List[dict] attribute_id_batch: list of dictionaries representing attribute records
        :param Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        :param List[string] attribute_ordered: list of attribute names in the same order as attribute_id_batch
        :param Dictionary database_ids: dictionary that maps attribute and value external ids to their database ids.
        :param string model_name: name of the model to be imported

        """

        attribute_id_numbers = models.execute_kw(db, uid, password, 'product.attribute', 'create', [attribute_id_batch])
        value_batch = []
        MAX_BATCH_SIZE = 100
        val_external_id_list = []

        attribute_model_metadata = []
        for i in range(len(attribute_id_numbers)):
            attribute_id_number = attribute_id_numbers[i]
            attribute = attribute_ordered[i]
            attribute_external_id = attr_val_dict[attribute]['attribute_external_id']
            database_ids[attribute_external_id] = attribute_id_number

            attribute_model_metadata.append({
                'model': 'product.attribute',
                'module': 'base',
                'res_id': attribute_id_number,
                'name': attribute_external_id
            })

            val_dict = attr_val_dict[attribute]['values']
            for val in val_dict.keys():
                if len(value_batch) >= MAX_BATCH_SIZE:
                    self.val_batch_calls(db, uid, password, models, value_batch,attr_val_dict,database_ids,val_external_id_list,model_name)
                    value_batch = []
                    val_external_id_list = []

                value_external_id = val_dict[val]
                val_external_id_list.append(value_external_id)
                value_batch.append({
                    'name': val,
                    'attribute_id': attribute_id_number,
                })

        if len(value_batch) > 0:
            self.val_batch_calls(db, uid, password, models, value_batch,attr_val_dict,database_ids,val_external_id_list,model_name)

        models.execute_kw(db, uid, password, 'ir.model.data', 'create', [attribute_model_metadata])


    def val_batch_calls(self, db, uid, password, models, value_id_batch,attr_val_dict,database_ids,val_extern_id_list, model_name):

        """
        makes api calls to create values in the database

        :param string db: name of the database
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param List[dict] value_id_batch: list of dictionaries representing value records
        :param Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        :param Dictionary database_ids: dictionary that maps attribute and value external ids to their database ids.
        :param string model_name: name of the model to be imported
        
        """
        value_id_numbers = models.execute_kw(db, uid, password, 'product.attribute.value', 'create', [value_id_batch])

        value_model_metadata = []

        for i in range(len(value_id_numbers)):
            value_id_number = value_id_numbers[i]
            attribute_id_number = value_id_batch[i]['attribute_id']
            models.execute_kw(db, uid, password, 'product.attribute', 'write', [[attribute_id_number], {
                    'value_ids': [(4, value_id_number, 0)]
                }])
            value_external_id = val_extern_id_list[i]
            database_ids[value_external_id] = value_id_number

            value_model_metadata.append({
                'model': 'product.attribute.value',
                'module': 'base',
                'name': value_external_id,
                'res_id': value_id_number
            })
        
        models.execute_kw(db, uid, password, 'ir.model.data', 'create', [value_model_metadata])


    def add_attributes_and_values(self, db, uid, password, models, database_ids, attr_val_dict, product_field_information,fields,columns):
       
        """
        This function creates new product.template records. It then adds the corresponding attribute lines to those records.
        Input:
        :param string db: name of the database
        :param int uid: user id for xmlrpc 
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param Dictionary database_ids: dictionary that maps attribute and value external ids to their database record ids

        """

        output_df = pd.read_csv('../data/outputdata.csv')
        output_df.rename(columns = lambda x: x.strip().lower(), inplace=True)

        parent_model_batch = [] 
        attribute_lines_batch = []
        product_ids = [] 

        BATCH_SIZE = 1000

        curr_product_id = -1

        col_name = None

        # find columns that corresponds to name field
        for i in range(len(fields)):
            if fields[i].lower() == 'name':
                col_name = columns[i].lower()
                break

        for row in range(0, len(output_df)):

            if row % 50 == 0: #status update
                print(row)

            # check if new record needs to be created
            if not pd.isna(output_df[col_name][row]):
                if len(parent_model_batch) > BATCH_SIZE:
                        self.batch_create_calls(db, uid, password, models, parent_model_batch, attribute_lines_batch)
                        parent_model_batch = []
                        product_ids = []
                        attribute_lines_batch = []
                        curr_product_id = -1
                
                new_product_fields = {} 
                new_product_attr_vals = {}
                curr_product_id += 1
                
                for col in output_df.columns:      
                    if col != "value" and col != "attribute":
                        col = col.lower()
                        field_name = product_field_information[col]['name']
                        field_type = product_field_information[col]['type']
                        field_val = output_df[col][row]
                        if field_type == 'many2one':
                            new_product_fields[field_name] = self.find_m2o_record(db, uid, password, models, product_field_information[col]['relation'], field_val)
                        elif field_type != 'many2many' and field_type != 'one2many':
                            new_product_fields[field_name] = self.convert_field_data_type(field_type, field_val)
                        else:
                            if field_name in new_product_fields:
                                new_product_fields[field_name].append(self.link_field_to_model(db, uid, password, models, field_val, product_field_information[col]['relation']))                    
                            else:
                                new_product_fields[field_name] = [self.link_field_to_model(db, uid, password, models, field_val, product_field_information[col]['relation'])]
                parent_model_batch.append(new_product_fields)
                    

            attribute_external_id = output_df['attribute'][row]


            if not pd.isna(attribute_external_id) and curr_product_id != -1:

                # curr_product_id is a placeholder that represents an index in parent_model_batch 
                # this index represents a product that the attribute lines will be added to
                
                attribute_id_number = database_ids[attribute_external_id]

                value_external_ids_list = output_df["value"][row].split(',')

                for val in range(0, len(value_external_ids_list)):
                    value_external_ids_list[val] = (4, database_ids[value_external_ids_list[val]], 0)

                attribute_lines_batch.append({
                    'product_tmpl_id': curr_product_id,
                    'attribute_id': attribute_id_number,
                    'value_ids': value_external_ids_list
                })

                product_ids.append(curr_product_id)

        if len(parent_model_batch) > 0:
            self.batch_create_calls(db, uid, password, models, parent_model_batch, attribute_lines_batch)
            parent_model_batch = []
            product_ids = []
            attribute_lines_batch = []
            curr_product_id = -1


    def convert_field_data_type(self, field_type, field_val):

        """
        helper function that casts data in the file to match the field type for basic fields
        this function is only called in add_attributes_and_values

        :param string field_type: type of the field
        :param string field_val: value of the field
        :rtype 
        """

        if field_type == 'integer':
            try:
                return int(field_val.replace(' $',''))
            except:
                return 0  
        elif field_type == 'monetary' or field_type =='float':
            try:
                return float(field_val.replace(' $',''))
            except:
                return 0.0
        elif field_type == 'boolean':
            return str(field_val).lower() == 'true'
        else:
            return str(field_val)


    #TODO: remove creation of models, replace with error warning
    def link_field_to_model(self, db, uid, password, models, field_val, comodel):

        """
        helper function to handle one2many and many2many fields
        This will try to match to an existing record by comparing the name from the csv file 
        to the name of the record via case insensitive string match. If no match can be found, then it will 
        create a new record with the name from the csv file.
        This function is only called in add_attributes_and_values.

        :param string db: database name
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param string field_val: value of the cell in the csv file
        :param string comodel: Name of the comodel for the field. This the model that the funcion will search for/create.
        :rtype (int, int, int): A tuple that represents a link command. It will be of the form (4, model_id, 0). 
        """

        existing_model_records = models.execute(db, uid, password, comodel, 'search_read')
        record_match = None
        for record in existing_model_records:
            if record['name'].lower() == str(field_val).lower():
                record_match = record['id']
                break
        if record_match:
            return (4, record_match, 0)
        else:
            new_record = models.execute_kw(db, uid, password, comodel, 'create', {
                'name': field_val
            })
            return (4, new_record, 0)


    def batch_create_calls(self, db, uid, password, models, parent_model_batch, attribute_lines_batch):

        """
        Helper function to make create api calls. Implements batching to improve runtime.
        This function is only called in add_attributes_and_values.

        :param string db: database name
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object for making xmlrpc calls
        :param list[Dictionary] parent_model_batch: each dictionary represents a record of the given model e.g. product.template
        :param list[Dictionary] attribute_lines_batch: each dictionary represents a record of the attribute.line model
        :param list[int] product_ids: list of database ids of records of the given model
        :param list[Dictionary] attribute_lines_batch: each dictionary represents a record of product.attribute.line.

        """
        product_db_ids = models.execute_kw(db, uid, password, 'product.template', 'create', [parent_model_batch])
        for attr_line in attribute_lines_batch:
            attr_line['product_tmpl_id'] = product_db_ids[attr_line['product_tmpl_id']]
        attribute_lines_ids = models.execute_kw(db, uid, password, 'product.template.attribute.line', 'create', [attribute_lines_batch])


    #TODO: raise error instead of creating new model
    def find_m2o_record(self, db, uid, password, models, relation, field_val):

        """
        helper function to find the database id of a record that is linked to a m2o field

        :param string db: database name
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object for making xmlrpc calls
        :param Dictionary product_field_information: field information for the model
        :param string relation: name of the comodel that the field is linked to
        :rtype int: database id of the record
        """

        record_id = models.execute_kw(db, uid, password, relation, 'search_read', [[['name', '=', field_val]]])
        if len(record_id) > 0:
            return record_id[0]['id']
        else:
            return models.execute_kw(db, uid, password, relation, 'create', [{
                'name': field_val
            }])


class DirtyToAttributeValues():
    # Default values
    display_type = "Radio"
    create_variant = "Instantly"
    visibility = "Visible"


    def get_dirty_data(self, dirtydata):
        """Returns dirty data csv into a dataframe.

        :param str dirtydata: String of file name 
        """

        return pd.read_csv(BytesIO(dirtydata))


    def list_all_columns(self, dirty_data):
        """Returns list of all columns in the dirty data dataframe.
        
        :param df dirty_data: Dataframe of dirty data
        :return: List of all columns
        :rtype: list
        """

        return dirty_data.columns


    def get_attribute_names(self, input_array, all_columns):
        """Get column name of all_columns in specified input_array.
        
        :param list input_array: All indexes of attributes
        :param list all_columns: List of all colummns in a dataframe
        :return: All column names of a list of columns
        :rtype: list
        """

        array = []
        print('input_array: ', input_array)
        print('all_columns: ', all_columns)
        for value in input_array:
            value = ord(value.lower())-97
            array.append(all_columns[value])
        print('array: ', array)
        return array


    def get_external_ids(self, name_list):
        """Creates external IDs for all names.
        
        :param list name_list: List of all names
        :return: List of all external IDs
        :rtype: list
        """
        ids_list = []
        for cell in name_list:
            if cell in ids_list and cell != " ":
                ids_list.append(" ")
            else:
                ids_list.append("attribute" + "_" + cell.lower())
        return ids_list


    def get_value_id_name(self, column_name, dirty_data):
        """Creates value_id/name.
        
        :param str column_name: Name of a column in dirty_data
        :param df dirty_data: Dirty data dataframe
        :return: List of value_id/names for a given column_name
        :rtype: list
        """

        value_id_names = []
        for value in dirty_data[column_name].tolist():
            if value not in value_id_names:
                value_id_names.append(value)
        return value_id_names


    def create_excel(self, df):
        """Converts dataframe into a excel file.
        
        :param df df: Dataframe to convert
        """
        return df.to_excel('attr_val.xlsx')


    # Create the data to be added to the new dataframe for the output csv
    # Creates value_id/id
    # Appends values into the data and returns a dataframe with data
    def create(self, input_array, dirtydata):
        #creates dirty data dataframe
        print('about to read dirty')
        dirty_data = self.get_dirty_data(dirtydata)
        print('dirty data read')
        #all columns of the dirty_data dataframe
        all_columns = self.list_all_columns(dirty_data)
        #get all attribute names from all_columns
        attribute_names = self.get_attribute_names(input_array, all_columns)
        #create ids from names_list
        external_ids = self.get_external_ids(attribute_names)
        data = []
        count = 0
        for name in attribute_names:
            value_id_names = self.get_value_id_name(name, dirty_data)
            id_num = 1
            prev = ""
            for value in value_id_names:
                if not isinstance(value, str):
                    continue
                #create value_ids/id
                value_id_id = name.lower() + "_" + str(id_num)
                id_num = id_num + 1
                if prev == name:
                    data.append(["","","","","",value,value_id_id])
                else:
                    data.append([name, external_ids[count], self.display_type, self.create_variant, self.visibility, value, value_id_id.lower()])
                prev = name
            count = count + 1
        df = pd.DataFrame(data, columns=["name", "id", "display_type", "create_variant", "visibility", "value_ids/name", "value_ids/id"]).set_index('name')
        return df


    # Creates csv for dataframe
    def main(self, dirtydata, input_array):
        print('main called')
        df = self.create(input_array, dirtydata)
        writer = BytesIO()
        df.to_excel(writer, engine='openpyxl')
        writer.seek(0)
        return writer.read()


class DirtyToClean():
    def create_attr_val_dict(self):
        #Testing
        attr_val_df = pd.read_excel('../data/attr-val.xlsx')

        attr_val_dict = {}
        currDict = {}
        currCategory = None

        for row in range(0, len(attr_val_df)): 
            if not pd.isna(attr_val_df['name'][row]):  
                if currCategory:
                    attr_val_dict[currCategory] = currDict
                currCategory = str(attr_val_df['name'][row]).replace(' ','_').lower() #Replace space with underscore for consistency
                currDict = {}

            currDict[str(attr_val_df['value_ids/name'][row]).replace(' ','_').lower()] = str(attr_val_df['value_ids/id'][row])

        if currCategory:
            attr_val_dict[currCategory] = currDict

        return attr_val_dict
    #############################################################################################
    #input: headers from the input file, data of the rest of the rows, and the parents and children column numbers
    #output: a dictionary of the following format:
    # Dictionary:{ItemName: [parentVal1, parentVal2,...]

    def create_item_dict(self, inHeader,inRows,parents,children):
        parent_cols = []
        children_cols = []
        # converting columns in letter to index of array
        for letter in parents:
            
            parent_cols.append(ord(letter.lower())-97)
        for letter in children:
            
            children_cols.append(ord(letter.lower())-97)
        attributes = []
        for col in children_cols:
            attributes.append(inHeader[col])
        item_set = []
        for item in inRows:
            data = []
            for i in parent_cols:
                data.append(item[i])
                
            #looping through the attributes, add attribute and value to dictionary
            
            attr_pairs = []
            #cleaning all the input strings, and replacing spaces with underscores, converting to lowercase for all letters
            for i in range(0,len(attributes)):
                attr_pairs.append((str(attributes[i]).replace(' ','_').lower(),str(item[children_cols[i]]).replace(' ','_').lower() ))
            data.append(attr_pairs)
            item_set.append(data)
        return item_set


    #input: item_set: dictionary consisting of item name as key and parent col values as value
    #       outHeader: the selected header from the original input file that should go into the output
    #       id_dict: dictionary consists of the attribute name as key and the id as value
    #output: writing to outputdata.csv for a clean output
    def output_clean_data(self, item_set,outHeader,id_dict):
        # buffer = BytesIO()
        # f = open('../data/outputdata.csv','w')
        # writer = csv.writer(f)
        # writer.writerow(outHeader)
        output_rows = []
        # output_rows.append(outHeader)
        count = 0
        for item in item_set:
            row = []
            parents = item[0:-1]
            parent_len = len(parents)
            attributes = item[-1]
            attr_len = len(attributes)
            attr_start = 0
            for val in parents:
                row.append(val)
            
            if len(attributes) > 0:
                
                attr0,val0 = attributes[attr_start]
                
                while val0 == '' and attr_start < attr_len:
                    attr_start+=1
                    attr0,val0 = attributes[attr_start]

                if val0 != '':
                    row.append("attribute_"+str(attr0).replace(' ','_').lower())
                    row.append(id_dict[attr0][val0])
            
            # writer.writerow(row)
            output_rows.append(row)
            count+=1
            
            
            for i in range(attr_start+1,len(attributes)):
                attr,val = attributes[i]
                #skipping empty value rows
                if val == '':
                    continue
                temprow = []
                for j in range(parent_len):
                    temprow.append('')
                temprow.append("attribute_"+str(attr).replace(' ','_').lower())
                temprow.append(id_dict[attr][val])
                # writer.writerow(temprow)
                output_rows.append(row)
                count+=1
        df = pd.DataFrame(output_rows, outHeader).set_index(outHeader[0])
        writer = BytesIO()
        df.to_excel(writer, engine='openpyxl')
        writer.seek(0)
        return writer.read()
        # return df
        
 
            
            
    #Input: 1: '[dirtydata].csv', replace dirtydata with actual file name
    #       2: letter of parent columns in a comma separated list
    #         for instance, in the example file DEV | 01 Client Dirty Data, input would be ['d','b','c','e','f','g','h','i','j','k','l','m','n'] (not case-sensitive)
    #       3: letter of children columns in a comma separated list

    #Output: outputdata.csv
    def main(self,dirtydata,parents,children):
        # csv_data = base64.b64decode('your binary field')
        # data_file = io.StringIO(csv_data.decode("utf-8"))
        # data_file.seek(0) 
        input_file = BytesIO(dirtydata)
        # byte_str = buffer.getvalue().decode('utf-8')
        # print(byte_str)
        csvreader=csv.reader(input_file, delimiter=',')        # byte_str = buffer.getvalue().decode('utf-8')
        # print(byte_str)
        inHeader = []
        inHeader = next(csvreader)
        print("\n\n\n")
        print("inheader is ", inHeader)
        print("\n\n\n")
        inRows = []
        parent_cols = []
        outheader = []
        # converting columns in letter to index of array
        for letter in parents:
            parent_cols.append(ord(letter.lower())-97)
    
        for row in csvreader:
            inRows.append(row)
        for i in parent_cols:
            outheader.append(inHeader[i]) 
        outheader.append('Attribute')
        outheader.append('Value')
        file.close()
        item_set = self.create_item_dict(inHeader,inRows,parents,children)
        id_dict = self.create_attr_val_dict()
        return self.output_clean_data(item_set,outheader,id_dict)