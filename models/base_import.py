from odoo import models, fields
import pandas as pd
import csv
import base64
import time
import numpy as np
from xmlrpc import client
from io import BytesIO
import openpyxl

#TODO: remove extra param from execute_Import and from rpc call in base_import_actions.js
#TODO: add external dependencies in manifest
#TODO: add support for excel upload
#TODO: option to ignore field
#TODO: update js state machine transition
#Requires limit-time-real 99999 flag

class BSAImport(models.TransientModel):
    _inherit = 'base_import.import'

    attr_val_file = fields.Binary('Attribute/Value File', help="File containing attribute/value data generated by cleaning script", attachment=False) 
    clean_file = fields.Binary('Clean File', help="File containing clean data generated by cleaning script", attachment=False)

    def execute_import(self, user, password, db, url, fields, columns, model_name):
        print('func called')
        """
        Driver function for the class
        This function is the main function that is called to run the script

        :param string user: the username of the user, typically the email address
        :param string password: an api key provided by the user
        :param string url: the url of the odoo server
        :param string db: the database name
        :param list[string] fields: a list of fields to be imported
        :param list[string]columns: a list of columns.
        :param string model_name: the name of the model to be imported
        :rtype: None

        Whenever possible, we create multiple records with one api call instead of creating one record at a time 
        in order to reduce unnecessary overhead
        This is why the functions that create records, such as 
        create_attribute_records and add_attributes_and_values have helper functions to make api calls

        
        """

        # hardcoded dev values
        # user = 'admin'
        # password = 'b7964650d8424f40dee5bbbc21fe77af060b05dc'
        # db = 'import-script'
        # url = 'http://localhost:8069'
        

        start = time.time()
        #TODO: change js state if error

        common = client.ServerProxy('{}/xmlrpc/2/common'.format(url))
        uid = common.authenticate(db, user, password, {})
        models = client.ServerProxy('{}/xmlrpc/2/object'.format(url))


        ALLOWED_FILE_TYPES = ['csv', 'xlsx', 'xls']
        print(self.file_type)
        # if (self.file_type not in ALLOWED_FILE_TYPES):
        #     raise ValueError("File type not allowed. Only .csv, .xlsx and .xls files are allowed")
        
        fields, columns, parents, children = self.parse_inputs(fields, columns)

        # parents = [0, 3, 4, 5, 11, 12, 13]
        # children = [1, 2, 6, 7, 8, 9, 10]

        # print('fields: ', fields)
        # print('columns: ', columns)
        # print('parents: ', parents)
        # print('children: ', children)

        #Generates attr-val file
        attr_val_generator = DirtyToAttributeValues()
        attr_val_file = attr_val_generator.main(self.file, children) #TODO: change function to match integer input

        self.write({
            'attr_val_file': attr_val_file,
        })

        attr_val_dict = self.create_attr_val_dict(fields, columns)
        print('dict created \n\n\n\n\n\n\n')
        #TODO: fix capitalization
        #Generates clean file
        clean_generator = DirtyToClean()
        clean_file = clean_generator.main(self.file, attr_val_dict, parents, children)

        self.write({
            'clean_file': clean_file
        })
        print('clean file created \n\n\n\n\n\n\n')

        #TESTS
        # pd.options.display.max_columns = None
        # clean_df = pd.read_excel(BytesIO(clean_file), engine='openpyxl')
        # print(clean_df.head(50))

        
        database_ids = self.create_attribute_records(db, uid, password, models, attr_val_dict, model_name)
        print('database ids created \n\n\n\n\n')
        product_field_information = self.get_field_information(db, uid, password, models, fields, columns)
        print('field information created \n\n\n\n\n')
        if not product_field_information:
            print('field info is null')
            return None
        self.add_attributes_and_values(db, uid, password, models, database_ids, attr_val_dict, product_field_information,fields,columns)
        print('attr and vals added \n\n\n\n\n')
        end = time.time()
        print(end - start)

        return []


    def parse_inputs(self, fields, columns):
        parent_columns = []
        parent_fields = []
        parent_indices = []
        child_columns = []

        for i in range(len(fields)):
            if (fields[i] == 'child_column'):
                child_columns.append(i)
            else:
                parent_columns.append(columns[i])
                parent_fields.append(fields[i])
                parent_indices.append(i)
        
        return parent_fields, parent_columns, parent_indices, child_columns



    def create_attr_val_dict(self,fields,columns):

        """
        Convert attribute/value data to a dictionary

        :param list[string] fields: a list of fields to be imported
        :param list[string]columns: a list of columns corresponding to the fields
        :rtype Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        
        There are three layers of dictionarys in attr_val_dict:
        Outermost dictionary has attribute names as keys and dictionaries as values
        The middle layer has two hardcoded keys:
        'attribute_external_id', which is the external id of the attribute
        'values_external_id', which is another dictionary
        The innermost dictionary's keys are the names of the values and the values are the external ids of the values
        
        
        Example 
        Original excel file
        Attribute_Name,Attribute_External_ID,Value_Name,Value_External_ID
        Color of Car Body,car_body_color,White,car_body_white
        ,,Green,car_body_green
        Color of Car Trim,car_trim_color,White,car_trim_white
        ,,Green,car_trim_green
        
        create_attr_val_dict() will return:
        {
            'Color of Car Body', {
                'attribute_external_id': 'car_body_color',
                'values': {
                    'White': 'car_body_white',
                    'Green': 'car_body_green'
                }
            }
            'Color of Car Trim', {
                'attribute_external_id': 'car_trim_color'
                'values': {
                    'White': 'car_trim_white',
                    'Green': 'car_trim_green'
                }
            }
        }
        """

        attr_val_df = pd.read_excel(BytesIO(self.attr_val_file), engine='openpyxl')

        attr_val_dict = {}
        curr_attribute = None
        
        for row in range(0, len(attr_val_df)):
            if not pd.isna(attr_val_df['name'][row]):            
                curr_attribute = str(attr_val_df['name'][row]).strip()
                attr_val_dict[curr_attribute] = {}
                attr_val_dict[curr_attribute]['attribute_external_id'] = attr_val_df['id'][row]
                attr_val_dict[curr_attribute]['values'] = {}

            curr_val_name = str(attr_val_df['value_ids/name'][row]).strip()
            curr_val_external_id = str(attr_val_df['value_ids/id'][row])
            
            attr_val_dict[curr_attribute]['values'][curr_val_name] = curr_val_external_id

        return attr_val_dict

    def create_attribute_records(self, db, uid, password, models, attr_val_dict, model_name):

            CREATE_VARIANT_DEFAULT = 'always'
            DISPLAY_TYPE_DEFAULT = 'radio'
            VISIBILITY_DEFAULT = 'visibile'
            attribute_id_batch = [] #keeping the batch
            MAX_BATCH_SIZE = 100
            database_ids = {}
            #TODO: implement duplicate checking
            attribute_ordered = [] #storing the attributes for each attribute in the same order as the keys of the dictionary\
            existent_attribute_to_overwrite = []
            for attribute in attr_val_dict.keys():
                check, id = self.check_attribute_existence(attr_val_dict,attribute,db,uid,password,models,database_ids)
                if check:
                    existent_attribute_to_overwrite.append((attribute,id))
                    
                    continue
                #check attribute['attribute_external_id'], do a read, if exist, append to to_write array, continue
                if len(attribute_id_batch) >= MAX_BATCH_SIZE:
                    self.attribute_batch_calls(self, db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids, model_name)
                    attribute_id_batch = []
                    attribute_ordered = []

                #list of dictionary ids
                attribute_id_batch.append({
                    'name': attribute,
                    'create_variant': CREATE_VARIANT_DEFAULT,
                    'display_type': DISPLAY_TYPE_DEFAULT,
                })


                attribute_ordered.append(attribute)
            
            if len(attribute_id_batch) > 0:
                self.attribute_batch_calls(db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids, model_name)
            self.overwrite_existing_records(db,uid,password,models,existent_attribute_to_overwrite,attr_val_dict,database_ids)
            return database_ids


    def overwrite_existing_records(self,db,uid,password,models,to_write,attr_val_dict,database_ids):
        for (attribute,attribute_id_number) in to_write:
            #overwrite the name of the attribute
            models.execute_kw(db,uid,password,'product.attribute','write',[[attribute_id_number],{'name':attribute}])
            #overwrite the values of the attribute
            val_dict = attr_val_dict[attribute]['values']
            for val in val_dict.keys():
                value_external_id = val_dict[val]
                [val_record] = models.execute_kw(db,uid,password,'ir.model.data','search_read',[[['name','=',value_external_id]]],{'fields':['res_id']})
                
                # print("Record read is ", val_record)
                if len(val_record) > 0:
                    #overwrite v
                    value_id_number = val_record['res_id']
                    # print('val is num is', value_id_number)
                    # print('attr id num is', attribute_id_number)
                    models.execute_kw(db, uid, password, 'product.attribute.value', 'write', [[value_id_number],{
                        'name': val,
                        'attribute_id': attribute_id_number,
                    }])
                    models.execute_kw(db, uid, password, 'product.attribute', 'write', [[attribute_id_number], {
                        'value_ids': [(4, value_id_number, 0)]
                    }])
                else:
                    # print("######################creating\n\n\n\n")
                    value_id_number = models.execute_kw(db, uid, password, 'product.attribute.value', 'create', [{
                        'name': val,
                        'attribute_id': attribute_id_number,
                    }])

                    models.execute_kw(db, uid, password, 'product.attribute', 'write', [[attribute_id_number], {
                        'value_ids': [(4, value_id_number, 0)]
                    }])
                    #:TODO: check if this external id needs to be kept in the database
                value_external_id = val_dict[val]
                database_ids[value_external_id] = value_id_number

        print("overwriting succeed")
        return


    def check_attribute_existence(self,attr_val_dict,attribute,db,uid,password,models,database_ids):
        attribute_external_id = attr_val_dict[attribute]['attribute_external_id']
        # print("\n\n aatr_id is ",attr_val_dict[attribute])
        attr_record = models.execute_kw(db,uid,password,'ir.model.data','search_read',[[['name','=',attribute_external_id]]], {'fields': ['res_id']})

        # print('priting record', attr_record)
        #[record] = models.execute_kw(db,uid,password,'product.attribute','read',[attribute_external_id])
        if len(attr_record) > 0:
            # print(attr_record)
            database_ids[attribute_external_id] = attr_record[0]['res_id']
            return True,attr_record[0]['res_id']
        else:
            return False, None


    def attribute_batch_calls(self, db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids,model_name):

        attribute_id_numbers = models.execute_kw(db, uid, password, 'product.attribute', 'create', [attribute_id_batch])
        value_batch = []
        MAX_BATCH_SIZE = 100
        val_external_id_list = []


        attribute_model_metadata = []
        for i in range(len(attribute_id_numbers)):
            attribute_id_number = attribute_id_numbers[i]
            attribute = attribute_ordered[i]
            attribute_external_id = attr_val_dict[attribute]['attribute_external_id']
            database_ids[attribute_external_id] = attribute_id_number

            attribute_model_metadata.append({
                'model': 'product.attribute',
                'module': 'base',
                'res_id': attribute_id_number,
                'name': attribute_external_id
            })

            val_dict = attr_val_dict[attribute]['values']
            for val in val_dict.keys():
                if len(value_batch) >= MAX_BATCH_SIZE:
                    self.val_batch_calls(db, uid, password, models, value_batch,attr_val_dict,database_ids,val_external_id_list,model_name)
                    value_batch = []
                    val_external_id_list = []

                value_external_id = val_dict[val]
                val_external_id_list.append(value_external_id)
                value_batch.append({
                    'name': val,
                    'attribute_id': attribute_id_number,
                })

        if len(value_batch) > 0:
            self.val_batch_calls(db, uid, password, models, value_batch,attr_val_dict,database_ids,val_external_id_list,model_name)

        models.execute_kw(db, uid, password, 'ir.model.data', 'create', [attribute_model_metadata])


    def val_batch_calls(self, db, uid, password, models, value_id_batch,attr_val_dict,database_ids,val_extern_id_list, model_name):
        value_id_numbers = models.execute_kw(db, uid, password, 'product.attribute.value', 'create', [value_id_batch])

        value_model_metadata = []

        for i in range(len(value_id_numbers)):
            value_id_number = value_id_numbers[i]
            attribute_id_number = value_id_batch[i]['attribute_id']
            models.execute_kw(db, uid, password, 'product.attribute', 'write', [[attribute_id_number], {
                    'value_ids': [(4, value_id_number, 0)]
                }])
            value_external_id = val_extern_id_list[i]
            database_ids[value_external_id] = value_id_number

            value_model_metadata.append({
                'model': 'product.attribute.value',
                'module': 'base',
                'name': value_external_id,
                'res_id': value_id_number
            })
        
        models.execute_kw(db, uid, password, 'ir.model.data', 'create', [value_model_metadata])


    def create_attribute_records_2(self, db, uid, password, models, attr_val_dict, model_name):

        """
        Reads from attribute-value excel file and creates corresponding attribute and value records in the database
        Note that there are hardcoded default values for the fields create_variant and display_type.
        returns a dictionary of database ids to avoid making api calls to search for records
 
        :param string db: name of the database.
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        :rtype Dictionary database_ids: dictionary that maps attribute and value external ids to their database ids.
        """

        CREATE_VARIANT_DEFAULT = 'always' #hardcoded default values as per requirements
        DISPLAY_TYPE_DEFAULT = 'radio'
        VISIBILITY_DEFAULT = 'visibile'
        attribute_id_batch = [] #keeping the batch
        MAX_BATCH_SIZE = 100
        database_ids = {}

        count = 0

        attribute_ordered = [] #storing the attributes for each attribute in the same order as the keys of the dictionary
        for attribute in attr_val_dict.keys():
            count += 1
            if count % 50 == 0:
                print(count)
            if len(attribute_id_batch) >= MAX_BATCH_SIZE:
                self.attribute_batch_calls(self, db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids, model_name)
                attribute_id_batch = []
                attribute_ordered = []

            #list of dictionary ids
            attribute_id_batch.append({
                'name': attribute,
                'create_variant': CREATE_VARIANT_DEFAULT,
                'display_type': DISPLAY_TYPE_DEFAULT,
            })


            attribute_ordered.append(attribute)

        if len(attribute_id_batch) > 0:
            self.attribute_batch_calls(db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids, model_name)
        return database_ids

    def get_field_information(self, db, uid, password, models, fields, columns):

        """
        retrieves informations about the fields of a given model from the database. currently hardcoded to product.template
        returns a dictionary that makes it much easiear to create records later

        :param string db: name of the database
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param list[string] fields: a list of fields to be imported
        :param list[string] columns: a list of columns corresponding to the fields
        :rtype Dictionary product_field_information: nested dictionary mapping column names to information about the corresponding field


        Example for product.template
        
        columns = ['Product Name', 'Company']
        fields = ['name', 'company_id']
        product_field_information = {
            'Product Name': {
                'name': 'name',
                'type': 'char',
            },
            'Company': {
                'name': 'company_id',
                'type': 'many2one',
                'relation': 'res.company',
            }
        }


        """
        
        product_template_fields = models.execute_kw(db, uid, password, 'product.template', 'fields_get', [])
        product_field_information = {}

        for i in range(0, len(columns)):
            columns[i].strip() 
            if columns[i] == 'attribute' or columns[i] == 'value':
                continue
            elif not fields[i]:      
                return None
            else:                    
                curr_col = columns[i]
                product_field_information[curr_col] = {}
                product_field_information[curr_col]['name'] = fields[i]
                field_type = product_template_fields[fields[i]]['type']
                product_field_information[curr_col]['type'] = field_type
                if field_type == 'many2many' or field_type == 'one2many'or field_type == 'many2one':
                    product_field_information[curr_col]['relation'] = product_template_fields[fields[i]]['relation']
        return product_field_information


    def attribute_batch_calls_2(self, db, uid, password, models, attribute_id_batch,attr_val_dict,attribute_ordered,database_ids,model_name):
        
        """
        makes api calls to create attributes and values in the database

        :param string db: name of the database
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param List[dict] attribute_id_batch: list of dictionaries representing attribute records
        :param Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        :param List[string] attribute_ordered: list of attribute names in the same order as attribute_id_batch
        :param Dictionary database_ids: dictionary that maps attribute and value external ids to their database ids.
        :param string model_name: name of the model to be imported

        """

        attribute_id_numbers = models.execute_kw(db, uid, password, 'product.attribute', 'create', [attribute_id_batch])
        value_batch = []
        MAX_BATCH_SIZE = 100
        val_external_id_list = []

        attribute_model_metadata = []
        for i in range(len(attribute_id_numbers)):
            attribute_id_number = attribute_id_numbers[i]
            attribute = attribute_ordered[i]
            attribute_external_id = attr_val_dict[attribute]['attribute_external_id']
            database_ids[attribute_external_id] = attribute_id_number

            attribute_model_metadata.append({
                'model': 'product.attribute',
                'module': 'base',
                'res_id': attribute_id_number,
                'name': attribute_external_id
            })

            val_dict = attr_val_dict[attribute]['values']
            for val in val_dict.keys():
                if len(value_batch) >= MAX_BATCH_SIZE:
                    self.val_batch_calls(db, uid, password, models, value_batch,attr_val_dict,database_ids,val_external_id_list,model_name)
                    value_batch = []
                    val_external_id_list = []

                value_external_id = val_dict[val]
                val_external_id_list.append(value_external_id)
                value_batch.append({
                    'name': val,
                    'attribute_id': attribute_id_number,
                })

        if len(value_batch) > 0:
            self.val_batch_calls(db, uid, password, models, value_batch,attr_val_dict,database_ids,val_external_id_list,model_name)

        models.execute_kw(db, uid, password, 'ir.model.data', 'create', [attribute_model_metadata])


    def val_batch_calls_2(self, db, uid, password, models, value_id_batch,attr_val_dict,database_ids,val_extern_id_list, model_name):

        """
        makes api calls to create values in the database

        :param string db: name of the database
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param List[dict] value_id_batch: list of dictionaries representing value records
        :param Dictionary attr_val_dict: nested dictionary of attribute and value names and external ids
        :param Dictionary database_ids: dictionary that maps attribute and value external ids to their database ids.
        :param string model_name: name of the model to be imported
        
        """
        value_id_numbers = models.execute_kw(db, uid, password, 'product.attribute.value', 'create', [value_id_batch])

        value_model_metadata = []

        for i in range(len(value_id_numbers)):
            value_id_number = value_id_numbers[i]
            attribute_id_number = value_id_batch[i]['attribute_id']
            models.execute_kw(db, uid, password, 'product.attribute', 'write', [[attribute_id_number], {
                    'value_ids': [(4, value_id_number, 0)]
                }])
            value_external_id = val_extern_id_list[i]
            database_ids[value_external_id] = value_id_number

            value_model_metadata.append({
                'model': 'product.attribute.value',
                'module': 'base',
                'name': value_external_id,
                'res_id': value_id_number
            })
        
        models.execute_kw(db, uid, password, 'ir.model.data', 'create', [value_model_metadata])


    def add_attributes_and_values_2(self, db, uid, password, models, database_ids, attr_val_dict, product_field_information,fields,columns):
       
        """
        This function creates new product.template records. It then adds the corresponding attribute lines to those records.
        Input:
        :param string db: name of the database
        :param int uid: user id for xmlrpc 
        :param string password: api key
        :param ServerProxy models: object that makes api calls
        :param Dictionary database_ids: dictionary that maps attribute and value external ids to their database record ids

        """
        print('about to read file \n\n\n')
        output_df = pd.read_excel(BytesIO(self.clean_file), engine='openpyxl')
        # print(output_df.head())
        output_df.rename(columns = lambda x: x.strip().lower(), inplace=True)

        parent_model_batch = [] 
        attribute_lines_batch = []
        product_ids = [] 

        BATCH_SIZE = 1000

        curr_product_id = -1

        col_name = None

        # find columns that corresponds to name field
        for i in range(len(fields)):
            if fields[i].lower() == 'name':
                print('name found \n \n \n \n \n')
                col_name = columns[i].lower()
                break
        
        if not col_name:
            print('name not found')
            return
        
        for row in range(0, len(output_df)):

            if row % 50 == 0: #status update
                print(row)

            # check if new record needs to be created
            if not pd.isna(output_df[col_name][row]):
                if len(parent_model_batch) > BATCH_SIZE:
                        self.batch_create_calls(db, uid, password, models, parent_model_batch, attribute_lines_batch)
                        parent_model_batch = []
                        product_ids = []
                        attribute_lines_batch = []
                        curr_product_id = -1
                
                new_product_fields = {} 
                new_product_attr_vals = {}
                curr_product_id += 1
                
                for col in output_df.columns:      
                    if col != "value" and col != "attribute":
                        col = col.lower()
                        field_name = product_field_information[col]['name']
                        field_type = product_field_information[col]['type']
                        field_val = output_df[col][row]
                        if field_type == 'many2one':
                            new_product_fields[field_name] = self.find_m2o_record(db, uid, password, models, product_field_information[col]['relation'], field_val)
                        elif field_type != 'many2many' and field_type != 'one2many':
                            new_product_fields[field_name] = self.convert_field_data_type(field_type, field_val)
                        else:
                            if field_name in new_product_fields:
                                new_product_fields[field_name].append(self.link_field_to_model(db, uid, password, models, field_val, product_field_information[col]['relation']))                    
                            else:
                                new_product_fields[field_name] = [self.link_field_to_model(db, uid, password, models, field_val, product_field_information[col]['relation'])]
                parent_model_batch.append(new_product_fields)
                    

            attribute_external_id = output_df['attribute'][row]


            if not pd.isna(attribute_external_id) and curr_product_id != -1:

                # curr_product_id is a placeholder that represents an index in parent_model_batch 
                # this index represents a product that the attribute lines will be added to
                
                attribute_id_number = database_ids[attribute_external_id]

                value_external_ids_list = output_df["value"][row].split(',')

                for val in range(0, len(value_external_ids_list)):
                    value_external_ids_list[val] = (4, database_ids[value_external_ids_list[val]], 0)

                attribute_lines_batch.append({
                    'product_tmpl_id': curr_product_id,
                    'attribute_id': attribute_id_number,
                    'value_ids': value_external_ids_list
                })

                product_ids.append(curr_product_id)

        if len(parent_model_batch) > 0:
            self.batch_create_calls(db, uid, password, models, parent_model_batch, attribute_lines_batch)
            parent_model_batch = []
            product_ids = []
            attribute_lines_batch = []
            curr_product_id = -1


    def add_attributes_and_values_2(self, db, uid, password, models, database_ids, attr_val_dict, product_field_information,fields,columns):
        output_df = pd.read_excel(BytesIO(self.clean_file), engine='openpyxl')
        output_df.rename(columns = lambda x: x.strip().lower(), inplace=True)

        parent_model_batch = [] 
        attribute_lines_batch = []
        product_ids = [] 

        BATCH_SIZE = 1000
        overwrite_model_batch = []
        overwrite_attr_lines_batch = []
        curr_product_id = -1

        col_name = None
        for i in range(len(fields)):
            if fields[i].lower() == 'name':
                col_name = columns[i].lower()
                break


        for row in range(0, len(output_df)):
            #TODO: implement duplicate checking
            if row % 50 == 0:
                print(row)

            if not pd.isna(output_df[col_name][row]):
                #check if exists
                curr_item_name = output_df[col_name][row]
 
                
                if len(parent_model_batch) > BATCH_SIZE:
                        self.batch_create_calls(db, uid, password, models, parent_model_batch, attribute_lines_batch)
                        parent_model_batch = []
                        product_ids = []
                        attribute_lines_batch = []
                        curr_product_id = -1
                

                new_product_fields = {} 
                new_product_attr_vals = {}
                curr_product_id += 1
                

                for col in output_df.columns:      
                    if col != "value" and col != "attribute":
                        col = col.lower()
                        field_name = product_field_information[col]['name']
                        field_type = product_field_information[col]['type']
                        field_val = output_df[col][row]
                        if field_type == 'many2one':
                            new_product_fields[field_name] = self.find_m2o_record(db, uid, password, models, product_field_information[col]['relation'], field_val)
                        elif field_type != 'many2many' and field_type != 'one2many':
                            new_product_fields[field_name] = self.convert_field_data_type(field_type, field_val)
                        else:
                            if field_name in new_product_fields:
                                new_product_fields[field_name].append(self.link_field_to_model(db, uid, password, models, field_val, product_field_information[col]['relation']))                    
                            else:
                                new_product_fields[field_name] = [self.link_field_to_model(db, uid, password, models, field_val, product_field_information[col]['relation'])] 
                exist, product_id = self.check_product_existence(models,db,uid,password,curr_item_name,overwrite_model_batch,overwrite_attr_lines_batch,new_product_fields)
                if not exist:
                    parent_model_batch.append(new_product_fields)
                    

            attribute_external_id = output_df['attribute'][row]
            if not pd.isna(attribute_external_id) and curr_product_id != -1:
                
                attribute_id_number = database_ids[attribute_external_id]

                value_external_ids_list = output_df["value"][row].split(',')

                for val in range(0, len(value_external_ids_list)):
                    value_external_ids_list[val] = (4, database_ids[value_external_ids_list[val]], 0)
                to_append = {
                    #'product_tmpl_id': curr_product_id,
                    'attribute_id': attribute_id_number,
                    'value_ids': value_external_ids_list
                }
                if not exist:
                    attribute_lines_batch.append(to_append)
                else:
                    overwrite_attr_lines_batch.append(to_append)
                product_ids.append(curr_product_id)

            if exist:
                new_p_fields, internal_id = overwrite_model_batch.pop()
                models.execute_kw(db,uid,password,'product.template','write',[[internal_id],new_p_fields])

                for attr_to_check in overwrite_attr_lines_batch:
                    curr_attr_id = attr_to_check['attribute_id']
                    attr_record = models.execute_kw(db,uid,password,'product.template.attribute.line','search_read',[[['attribute_id','=',curr_attr_id]]])
                    if len(attr_record) > 0:
                        print("\n\n")
                        print("id of attribute line record is ", attr_record[0]['id'])
                        models.execute_kw(db,uid,password,'product.template.attribute.line','write',[[attr_record[0]['id']],attr_to_check])
                    else:
                        models.execute_kw(db,uid,password,'product.template.attribute.line','create',[attr_to_check])
                #write here
                #


        if len(parent_model_batch) > 0:
            self.batch_create_calls(db, uid, password, models, parent_model_batch, attribute_lines_batch)
            parent_model_batch = []
            product_ids = []
            attribute_lines_batch = []
            curr_product_id = -1



    def add_attributes_and_values(self, db, uid, password, models, database_ids, attr_val_dict, product_field_information, fields, columns):

        clean_df = pd.read_excel(BytesIO(self.clean_file), engine='openpyxl')


        #Find column that matches to name field
        name_col = None
        for f in fields:
            if f.lower() == 'name':
                name_col = columns.index(f)
                break

        if not name_col:
            print('No name field found')
            #TODO: raise error
        
        #Create nested dictionary. outer key is product database id, inner key is attribute name, value is list of values
        product_attribute_dict = {}
        placeholder_product_id = 2929292929


        for row in range(0, len(clean_df)):
            if not pd.isna(clean_df[name_col][row]):
                curr_product_name = clean_df[name_col][row]
                self.check_product_existence(models, db, uid, password, curr_product_name, overwrite_model_batch, overwrite_attr_lines_batch, new_product_fields)



            
    def check_product_existence(self,models,db,uid,password,curr_item_name,overwrite_model_batch,overwrite_attr_lines_batch, new_product_fields):
        item_record = models.execute_kw(db,uid,password,'product.template','search_read',[[['name','=',curr_item_name]]], {'fields': ['id']})
        if len(item_record) > 0:
            overwrite_model_batch.append((new_product_fields,item_record[0]['id']))
            return True, item_record[0]['id']
        else:
            return False, None


    
    
    def convert_field_data_type(self, field_type, field_val):

        """
        helper function that casts data in the file to match the field type for basic fields
        this function is only called in add_attributes_and_values

        :param string field_type: type of the field
        :param string field_val: value of the field
        :rtype 
        """

        if field_type == 'integer':
            try:
                return int(field_val.replace(' $',''))
            except:
                return 0  
        elif field_type == 'monetary' or field_type =='float':
            try:
                return float(field_val.replace(' $',''))
            except:
                return 0.0
        elif field_type == 'boolean':
            return str(field_val).lower() == 'true'
        else:
            return str(field_val)


    #TODO: remove creation of models, replace with error warning
    def link_field_to_model(self, db, uid, password, models, field_val, comodel):

        """
        helper function to handle one2many and many2many fields
        This will try to match to an existing record by comparing the name from the csv file 
        to the name of the record via case insensitive string match. If no match can be found, then it will 
        create a new record with the name from the csv file.
        This function is only called in add_attributes_and_values.

        :param string db: database name
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param string field_val: value of the cell in the csv file
        :param string comodel: Name of the comodel for the field. This the model that the funcion will search for/create.
        :rtype (int, int, int): A tuple that represents a link command. It will be of the form (4, model_id, 0). 
        """
        # print('comodel is', comodel)
        existing_model_records = models.execute(db, uid, password, comodel, 'search_read')
        record_match = None
        for record in existing_model_records:
            name = record['name'][1]
            # print('\n \n \n name is ', name)
            if record['name'].lower() == str(field_val).lower():
                record_match = record['id']
                break
        if record_match:
            return (4, record_match, 0)
        else:
            print('Record not found')
            #TODO: add error raising


    def batch_create_calls(self, db, uid, password, models, parent_model_batch, attribute_lines_batch):
        product_db_ids = models.execute_kw(db, uid, password, 'product.template', 'create', [parent_model_batch])
        for attr_line in attribute_lines_batch:
            attr_line['product_tmpl_id'] = product_db_ids[attr_line['product_tmpl_id']]
        attribute_lines_ids = models.execute_kw(db, uid, password, 'product.template.attribute.line', 'create', [attribute_lines_batch])


    def batch_create_calls_2(self, db, uid, password, models, parent_model_batch, attribute_lines_batch):

        """
        Helper function to make create api calls. Implements batching to improve runtime.
        This function is only called in add_attributes_and_values.

        :param string db: database name
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object for making xmlrpc calls
        :param list[Dictionary] parent_model_batch: each dictionary represents a record of the given model e.g. product.template
        :param list[Dictionary] attribute_lines_batch: each dictionary represents a record of the attribute.line model
        :param list[int] product_ids: list of database ids of records of the given model
        :param list[Dictionary] attribute_lines_batch: each dictionary represents a record of product.attribute.line.

        """
        product_db_ids = models.execute_kw(db, uid, password, 'product.template', 'create', [parent_model_batch])
        for attr_line in attribute_lines_batch:
            attr_line['product_tmpl_id'] = product_db_ids[attr_line['product_tmpl_id']]
        attribute_lines_ids = models.execute_kw(db, uid, password, 'product.template.attribute.line', 'create', [attribute_lines_batch])


    #TODO: raise error instead of creating new model
    def find_m2o_record(self, db, uid, password, models, relation, field_val):

        """
        helper function to find the database id of a record that is linked to a m2o field

        :param string db: database name
        :param int uid: user id for xmlrpc
        :param string password: api key
        :param ServerProxy models: object for making xmlrpc calls
        :param Dictionary product_field_information: field information for the model
        :param string relation: name of the comodel that the field is linked to
        :rtype int: database id of the record
        """

        record_id = models.execute_kw(db, uid, password, relation, 'search_read', [[['name', '=', field_val]]])
        if len(record_id) > 0:
            return record_id[0]['id']
        else:
            return models.execute_kw(db, uid, password, relation, 'create', [{
                'name': field_val
            }])


class DirtyToAttributeValues():
    # Default values
    display_type = "Radio"
    create_variant = "Instantly"
    visibility = "Visible"


    def get_dirty_data(self, dirtydata):
        """Returns dirty data csv into a dataframe.

        :param str dirtydata: String of file name 
        """

        return pd.read_csv(BytesIO(dirtydata))


    def list_all_columns(self, dirty_data):
        """Returns list of all columns in the dirty data dataframe.
        
        :param df dirty_data: Dataframe of dirty data
        :return: List of all columns
        :rtype: list
        """

        return dirty_data.columns


    def get_attribute_names(self, input_array, all_columns):
        """Get column name of all_columns in specified input_array.
        
        :param list input_array: All indexes of attributes
        :param list all_columns: List of all colummns in a dataframe
        :return: All column names of a list of columns
        :rtype: list
        """

        array = []
        for value in input_array:
            #value = ord(value.lower())-97
            array.append(all_columns[value])
        return array


    def get_external_ids(self, name_list):
        """Creates external IDs for all names.
        
        :param list name_list: List of all names
        :return: List of all external IDs
        :rtype: list
        """
        ids_list = []
        for cell in name_list:
            if cell in ids_list and cell != " ":
                ids_list.append(" ")
            else:
                ids_list.append("attribute" + "_" + cell.lower())
        return ids_list


    def get_value_id_name(self, column_name, dirty_data):
        """Creates value_id/name.
        
        :param str column_name: Name of a column in dirty_data
        :param df dirty_data: Dirty data dataframe
        :return: List of value_id/names for a given column_name
        :rtype: list
        """

        value_id_names = []
        for value in dirty_data[column_name].tolist():
            if value not in value_id_names:
                value_id_names.append(value)
        return value_id_names


    def create_excel(self, df):
        """Converts dataframe into a excel file.
        
        :param df df: Dataframe to convert
        """
        return df.to_excel('attr_val.xlsx')


    # Create the data to be added to the new dataframe for the output csv
    # Creates value_id/id
    # Appends values into the data and returns a dataframe with data
    def create(self, input_array, dirtydata):
        #creates dirty data dataframe
        dirty_data = self.get_dirty_data(dirtydata)
        #all columns of the dirty_data dataframe
        all_columns = self.list_all_columns(dirty_data)
        #get all attribute names from all_columns
        attribute_names = self.get_attribute_names(input_array, all_columns)
        #create ids from names_list
        external_ids = self.get_external_ids(attribute_names)
        data = []
        count = 0
        for name in attribute_names:
            value_id_names = self.get_value_id_name(name, dirty_data)
            id_num = 1
            prev = ""
            for value in value_id_names:
                if not isinstance(value, str):
                    continue
                #create value_ids/id
                value_id_id = name.lower() + "_" + str(id_num)
                id_num = id_num + 1
                if prev == name:
                    data.append(["","","","","",value,value_id_id])
                else:
                    data.append([name, external_ids[count], self.display_type, self.create_variant, self.visibility, value, value_id_id.lower()])
                prev = name
            count = count + 1
        df = pd.DataFrame(data, columns=["name", "id", "display_type", "create_variant", "visibility", "value_ids/name", "value_ids/id"]).set_index('name')
        return df


    # Creates csv for dataframe
    def main(self, dirtydata, input_array):
        df = self.create(input_array, dirtydata)
        writer = BytesIO()
        df.to_excel(writer, engine='openpyxl')
        writer.seek(0)
        return writer.read()


class DirtyToClean():

    #############################################################################################
    #input: headers from the input file, data of the rest of the rows, and the parents and children column numbers
    #output: a dictionary of the following format:
    # Dictionary:{ItemName: [parentVal1, parentVal2,...]

    def create_item_dict(self, inHeader,inRows,parents,children):
        # parent_cols = []
        # children_cols = []
        # # converting columns in letter to index of array
        # for letter in parents:         
        #     parent_cols.append(ord(letter.lower())-97)
        # for letter in children:
        #     children_cols.append(ord(letter.lower())-97)
        attributes = []
        for col in children:
            attributes.append(inHeader[col])
        item_set = []
        
        for item in inRows:
            data = []
            for i in parents:
                data.append(item[i])
                
            #looping through the attributes, add attribute and value to dictionary
            
            attr_pairs = []
            #cleaning all the input strings, and replacing spaces with underscores, converting to lowercase for all letters
            for i in range(0,len(attributes)):
                #attr_pairs.append((str(attributes[i]).replace(' ','_').lower(),str(item[children_cols[i]]).replace(' ','_').lower() ))
                attr_pairs.append((str(attributes[i]),str(item[children[i]])))
            data.append(attr_pairs)
            item_set.append(data)
        return item_set


    #input: item_set: dictionary consisting of item name as key and parent col values as value
    #       outHeader: the selected header from the original input file that should go into the output
    #       id_dict: dictionary consists of the attribute name as key and the id as value
    #output: writing to outputdata.csv for a clean output
    def output_clean_data(self, item_set,outHeader,id_dict):
        # buffer = BytesIO()
        # f = open('../data/outputdata.csv','w')
        # writer = csv.writer(f)
        # writer.writerow(outHeader)
        output_rows = []
        # output_rows.append(outHeader)
        count = 0
        for item in item_set:

            row = []
            parents = item[0:-1]
            parent_len = len(parents)
            attributes = item[-1]
            attr_len = len(attributes)
            attr_start = 0
            for val in parents:
                row.append(val)

            if len(attributes) > 0:
                # print('attributes is', attributes)
                attr0,val0 = attributes[attr_start]
                
                while val0 == 'nan' and attr_start < attr_len:
                    attr_start+=1
                    attr0,val0 = attributes[attr_start]

                if val0 != 'nan':
                    row.append("attribute_"+str(attr0).replace(' ','_').lower())
                    # for key in id_dict.keys():
                    #     print('key is', key)
                    #     print(id_dict[key])
                    #     break
                    
                    row.append(id_dict[attr0]['values'][val0])
                    #TODO: fix

            # writer.writerow(row)
            output_rows.append(row)
            count+=1
            

            for i in range(attr_start+1,len(attributes)):
                attr,val = attributes[i]
                #skipping empty value rows
                if val == 'nan':
                    continue
                
                temprow = []
                for j in range(parent_len):
                    temprow.append('')
                temprow.append("attribute_"+str(attr).replace(' ','_').lower())
                # temp
                temprow.append(id_dict[attr]['values'][val])
                # writer.writerow(temprow)
                output_rows.append(temprow)
                count+=1

        # print("outputing row is", output_rows[0:10])
        df = pd.DataFrame(output_rows, columns=outHeader)
        # print("Parsed data frame ", df.head())
        writer = BytesIO()
        df.to_excel(writer, engine='openpyxl', index=False)
        writer.seek(0)
        return writer.read()
        # return df
        
 
            
            
    #Input: 1: '[dirtydata].csv', replace dirtydata with actual file name
    #       2: letter of parent columns in a comma separated list
    #         for instance, in the example file DEV | 01 Client Dirty Data, input would be ['d','b','c','e','f','g','h','i','j','k','l','m','n'] (not case-sensitive)
    #       3: letter of children columns in a comma separated list

    #Output: outputdata.csv
    def main(self,dirtydata,attr_val_dict,parents,children):

        input_file = BytesIO(dirtydata)

        df = pd.read_csv(input_file)        

        inHeader = []

        inRows = []
        # parent_cols = []
        outheader = []
        # converting columns in letter to index of array
        # for letter in parents:
        #     parent_cols.append(ord(letter.lower())-97)
        for i in range (len(df)):
            inRows.append(df.iloc[i].to_numpy().tolist())
 
        for col in df.columns:
            inHeader.append(col)

        for i in parents:
            outheader.append(inHeader[i]) 
        outheader.append('Attribute')
        outheader.append('Value')
        # file.close()
        # print("First ten lines of inrows ", inRows[0:10])
        print("length of the inrows  is ", len(inRows))
        item_set = self.create_item_dict(inHeader,inRows,parents,children)
        # print("Item set is ", item_set[0:10])
        # id_dict = self.create_attr_val_dict(attr_val_file)
        return self.output_clean_data(item_set,outheader,attr_val_dict)

#e6897cc4a67426d503cb5feaf6eb69e0788d0586
#TODO: fix attribute underscores
